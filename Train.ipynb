{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import matplotlib\n",
    "from scipy import ndimage, misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-fe552a99c67b>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\SimJaekyu\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\SimJaekyu\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./tmp/data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\SimJaekyu\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./tmp/data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\SimJaekyu\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting ./tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\SimJaekyu\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"./tmp/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cell end\n"
     ]
    }
   ],
   "source": [
    "class STN(object):\n",
    "    def __init__(self, sess, batch_size, epochs):\n",
    "        self.input_size = 28\n",
    "        self.output_size = 28\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.sess = sess\n",
    "        \n",
    "        self.initial = np.array([[1., 0., 0.], [0., 1., 0.]], dtype=np.float32)\n",
    "        self.initial = self.initial.flatten()\n",
    "        \n",
    "        self.initial = np.expand_dims(self.initial, axis=0)\n",
    "        \n",
    "\n",
    "        self.X = tf.placeholder(dtype=tf.float32, shape=[None, self.input_size, self.input_size, 1])\n",
    "        self.Y = tf.placeholder(dtype=tf.float32, shape=[None, self.output_size, self.output_size, 1])\n",
    "        #self.Output = tf.placeholder(dtype = tf.float32, shape=[None, self.output_size, self.output_size, 1])\n",
    "        \n",
    "        self.W1 = tf.Variable(tf.random_normal(shape=[3, 3, 1, 32], stddev=0.01))\n",
    "        self.W2 = tf.Variable(tf.random_normal(shape=[3, 3, 32, 64], stddev=0.01))\n",
    "        self.W3 = tf.Variable(tf.random_normal(shape=[3, 3, 64, 128], stddev=0.01))\n",
    "        self.W4 = tf.Variable(tf.random_normal(shape=[3, 3, 128, 256], stddev=0.01))\n",
    "        self.W5 = tf.Variable(tf.random_normal(shape=[3, 3, 256, 128], stddev=0.01))\n",
    "        self.W6 = tf.Variable(tf.random_normal(shape=[3, 3, 128, 64], stddev=0.01))\n",
    "        self.W7 = tf.Variable(tf.random_normal(shape=[7*7*64, 32], stddev=0.01))\n",
    "        self.W8 = tf.Variable(tf.zeros(shape=[32, 6]))\n",
    "        self.b8 = tf.Variable(self.initial)\n",
    "        \n",
    "        \n",
    "        self.model()\n",
    "        #self.Get_Pixel_Value()\n",
    "    \n",
    "    def Localisation_Net(self, img):\n",
    "        #img -> [batch, 28, 28, 1]\n",
    "        net = tf.nn.conv2d(img, self.W1, padding=\"SAME\", strides=[1, 1, 1, 1])\n",
    "        net = tf.nn.relu(net)\n",
    "        net = tf.nn.max_pool(net, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\")\n",
    "        \n",
    "        #net -> [batch, 14, 14, 32]\n",
    "        net = tf.nn.conv2d(net, self.W2, padding=\"SAME\", strides=[1, 1, 1, 1])\n",
    "        net = tf.nn.relu(net)\n",
    "        net = tf.nn.max_pool(net, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\")\n",
    "        \n",
    "        net = tf.nn.conv2d(net, self.W3, padding=\"SAME\", strides=[1, 1, 1, 1])\n",
    "        net = tf.nn.relu(net)\n",
    "        \n",
    "        net = tf.nn.conv2d(net, self.W4, padding=\"SAME\", strides=[1, 1, 1, 1])\n",
    "        net = tf.nn.relu(net)\n",
    "        \n",
    "        net = tf.nn.conv2d(net, self.W5, padding=\"SAME\", strides=[1, 1, 1, 1])\n",
    "        net = tf.nn.relu(net)\n",
    "        \n",
    "        net = tf.nn.conv2d(net, self.W6, padding=\"SAME\", strides=[1, 1, 1, 1])\n",
    "        net = tf.nn.relu(net)\n",
    "        \n",
    "        #net -> [batch, 7, 7, 64]\n",
    "        net = tf.reshape(net, [-1, 7*7*64])\n",
    "        net = tf.matmul(net, self.W7)\n",
    "        net = tf.nn.relu(net)\n",
    "        \n",
    "        #net -> [batch, 32]\n",
    "        net = tf.matmul(net, self.W8)\n",
    "        net = tf.add(net, self.b8)\n",
    "        \n",
    "        #net -> [batch, 6]\n",
    "        theta = net\n",
    "        return theta\n",
    "    \n",
    "        \n",
    "    def Grid_Generator(self, theta):\n",
    "        theta = tf.reshape(theta, shape=[-1, 2, 3])\n",
    "        \n",
    "        width = self.output_size\n",
    "        height = self.output_size\n",
    "        \n",
    "        #[-1.0 ~ 1.0] normalize\n",
    "        x = tf.linspace(-1.0, 1.0, width)\n",
    "        y = tf.linspace(-1.0, 1.0, height)\n",
    "        \n",
    "        #make xy grid(meshgrid)\n",
    "        x_t, y_t = tf.meshgrid(x, y)\n",
    "        \n",
    "        x_t_flat = tf.reshape(x_t, [-1])\n",
    "        y_t_flat = tf.reshape(y_t, [-1])\n",
    "        ones     = tf.ones_like(y_t_flat)\n",
    "        \n",
    "        #make grid with ones\n",
    "        grid = tf.stack([x_t_flat, y_t_flat, ones])\n",
    "        \n",
    "        #make batch size\n",
    "        grid = tf.expand_dims(grid, axis=0)\n",
    "        batch_grid = tf.tile(grid, tf.stack([self.batch_size, 1, 1]))\n",
    "        \n",
    "        theta = tf.cast(theta, 'float32')\n",
    "        batch_grid = tf.cast(batch_grid, 'float32')\n",
    "        \n",
    "        #theta x batch_grid\n",
    "        \n",
    "        batch_grid = tf.matmul(theta, batch_grid)\n",
    "        \n",
    "        #reshape\n",
    "        #print(np.shape(batch_grid))\n",
    "        batch_grid = tf.reshape(batch_grid, [self.batch_size, 2, width, height])\n",
    "        \n",
    "        return batch_grid\n",
    "    \n",
    "    def Get_Pixel_Value(self, img, x, y):\n",
    "        shape = np.shape(x)\n",
    "        batch_size = shape[0]\n",
    "        height = shape[1]\n",
    "        width = shape[2]\n",
    "\n",
    "        batch_idx = tf.range(0, batch_size)\n",
    "        batch_idx = tf.reshape(batch_idx, (batch_size, 1, 1))\n",
    "        b = tf.tile(batch_idx, (1, height, width))\n",
    "\n",
    "        indices = tf.stack([b, y, x], 3)\n",
    "\n",
    "        return tf.gather_nd(img, indices)\n",
    "        \n",
    "    def Bilinear_Sampler(self, img, grid):\n",
    "        x = grid[:, 0, :, :]\n",
    "        y = grid[:, 1, :, :]\n",
    "        \n",
    "        H = tf.shape(img)[1]\n",
    "        W = tf.shape(img)[2]\n",
    "        \n",
    "        max_x = tf.cast(W-1, 'int32')\n",
    "        max_y = tf.cast(H-1, 'int32')\n",
    "        zero = tf.zeros([], dtype = 'int32')\n",
    "        \n",
    "        x = tf.cast(x, 'float32')\n",
    "        y = tf.cast(y, 'float32')\n",
    "        \n",
    "        x = 0.5 * ((x + 1.0) * tf.cast(max_x-1, 'float32'))\n",
    "        y = 0.5 * ((y + 1.0) * tf.cast(max_y-1, 'float32'))\n",
    "        \n",
    "        #1 이하 값 없애기\n",
    "        x0 = tf.cast(tf.floor(x), 'int32')\n",
    "        x1 = x0 + 1\n",
    "        y0 = tf.cast(tf.floor(y), 'int32')\n",
    "        y1 = y0 + 1\n",
    "        \n",
    "        x0 = tf.clip_by_value(x0, zero, max_x)\n",
    "        x1 = tf.clip_by_value(x1, zero, max_x)\n",
    "        y0 = tf.clip_by_value(y0, zero, max_y)\n",
    "        y1 = tf.clip_by_value(y1, zero, max_y)\n",
    "        \n",
    "        # get pixel value at corner coords\n",
    "        Ia = self.Get_Pixel_Value(img, x0, y0)\n",
    "        Ib = self.Get_Pixel_Value(img, x0, y1)\n",
    "        Ic = self.Get_Pixel_Value(img, x1, y0)\n",
    "        Id = self.Get_Pixel_Value(img, x1, y1)\n",
    "\n",
    "        # recast as float for delta calculation\n",
    "        x0 = tf.cast(x0, 'float32')\n",
    "        x1 = tf.cast(x1, 'float32')\n",
    "        y0 = tf.cast(y0, 'float32')\n",
    "        y1 = tf.cast(y1, 'float32')\n",
    "\n",
    "        # calculate deltas\n",
    "        wa = (x1-x) * (y1-y)\n",
    "        wb = (x1-x) * (y-y0)\n",
    "        wc = (x-x0) * (y1-y)\n",
    "        wd = (x-x0) * (y-y0)\n",
    "\n",
    "        # add dimension for addition\n",
    "        wa = tf.expand_dims(wa, axis=3)\n",
    "        wb = tf.expand_dims(wb, axis=3)\n",
    "        wc = tf.expand_dims(wc, axis=3)\n",
    "        wd = tf.expand_dims(wd, axis=3)\n",
    "\n",
    "        # compute output\n",
    "        out = tf.add_n([wa*Ia, wb*Ib, wc*Ic, wd*Id])\n",
    "\n",
    "        return out\n",
    "        \n",
    "        \n",
    "    def load_data(self, rot = False, trans = False):\n",
    "        \"\"\"image, _ = mnist.train.next_batch(self.batch_size)#batch_xs, _ : image, label\n",
    "        image = np.reshape(image, [-1, 28, 28])\n",
    "        \n",
    "        angle = np.random.randint(0, 356, self.batch_size)\n",
    "        rotated_image = []\n",
    "        for i in range(self.batch_size):\n",
    "            tmp = ndimage.rotate(image[i], angle[i], reshape=False)\n",
    "            #tmp = cv2.resize(tmp, (40, 40))\n",
    "            rotated_image.append(tmp)\n",
    "        label_image = []\n",
    "        for i in range(self.batch_size):\n",
    "            #tmp = cv2.resize(image[i], (40, 40))\n",
    "            #label_image.append(tmp)\n",
    "            label_image.append(image[i])\n",
    "            \n",
    "        rotated_image = np.expand_dims(rotated_image, axis=3)    \n",
    "        label_image = np.expand_dims(label_image, axis=3)\"\"\"\n",
    "        \n",
    "        image, _ = mnist.train.next_batch(self.batch_size)#batch_xs, _ : image, label\n",
    "        image = np.reshape(image, [-1, 28, 28])\n",
    "\n",
    "        BLACK = [0, 0, 0]\n",
    "        translated_image = []\n",
    "\n",
    "        for i in range(len(image)):\n",
    "            array = np.random.randint(-30, 30, size=(2), dtype=np.int8)\n",
    "            translate_matrix = np.float32([[1, 0, array[0]],[0, 1, array[1]]])\n",
    "            constant = cv2.copyMakeBorder(image[i], 30, 30, 30, 30, cv2.BORDER_CONSTANT, value=BLACK)\n",
    "            img_translation = cv2.warpAffine(constant, translate_matrix, (88, 88))\n",
    "            img_translation = cv2.resize(img_translation, (28, 28))\n",
    "            translated_image.append(img_translation)\n",
    "            \n",
    "        label_image = []\n",
    "        for i in range(self.batch_size):\n",
    "            label_image.append(image[i])\n",
    "        translated_image = np.expand_dims(translated_image, axis = 3)\n",
    "        label_image = np.expand_dims(label_image, axis=3)\n",
    "        \n",
    "        #return label_image, rotated_image, angle\n",
    "        return label_image, translated_image\n",
    "        \n",
    "    def spatial_transformer(self, _input):\n",
    "        theta = self.Localisation_Net(_input)\n",
    "        grid = self.Grid_Generator(theta)\n",
    "        output = self.Bilinear_Sampler(_input, grid)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    \n",
    "    def model(self):\n",
    "        self.stn_output = self.spatial_transformer(self.X)\n",
    "        self.l2_loss = tf.nn.l2_loss((self.stn_output - self.Y) / self.batch_size)\n",
    "        self.loss = tf.reduce_mean(self.l2_loss)\n",
    "        \n",
    "        global_step = tf.Variable(0, trainable=False)\n",
    "        starter_learning_rate = 1e-06\n",
    "        lr = tf.train.exponential_decay(starter_learning_rate, global_step,100000, 0.333, staircase=True)\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate = lr).minimize(self.loss, global_step = global_step)\n",
    "        \n",
    "    def train(self):\n",
    "        data_size = 60000\n",
    "        batch_size = self.batch_size\n",
    "        total_batch = data_size//batch_size\n",
    "\n",
    "        loss_data = []\n",
    "        \n",
    "        SAVE_PATH = \"C:/Users/SimJaekyu/Documents/Jupyter Notebook/Spatial_Transformer_Net/Weight/Weight.ckpt\"\n",
    "        print(\"session start\")\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        saver = tf.train.Saver()\n",
    "        try:\n",
    "            saver.restore(self.sess, SAVE_PATH)\n",
    "            print(\"Existing Weight.ckpt file load\")\n",
    "            print(\"Training Start\")\n",
    "        except:\n",
    "            print(\"No Training Weight.ckpt exist\")\n",
    "            print(\"Make New Weight.ckpt file for training\")\n",
    "            print(\"Training Start\")\n",
    "        \n",
    "        loss_data = []\n",
    "        for epoch in range(self.epochs):#15\n",
    "            print(\"epoch\",epoch+1, \"start\")\n",
    "            for i in range(total_batch):#total_batch\n",
    "                #data load, batch 생성\n",
    "                label_img, translated_img = self.load_data()\n",
    "                #print(\"self.X's shape : \", np.shape(rotate_img), \"self.Y's shape : \", np.shape(label_img))\n",
    "                total_loss_opt, net_loss, predict = self.sess.run([self.optimizer, self.l2_loss, self.stn_output], feed_dict = {self.X : translated_img, self.Y : label_img})\n",
    "                loss_data.append(net_loss)\n",
    "\n",
    "            print(net_loss)\n",
    "            plt.plot(loss_data)\n",
    "            plt.show()\n",
    "            \n",
    "            test_index = 0\n",
    "            print(\"--------------------predict--------------------\")\n",
    "            predict = np.squeeze(predict)\n",
    "            plt.imshow(predict[test_index])\n",
    "            plt.show()\n",
    "            print(\"------------------rotate_img-------------------\")\n",
    "            translated_img = np.squeeze(translated_img)\n",
    "            plt.imshow(translated_img[test_index])\n",
    "            plt.show()\n",
    "            print(\"------------------label_img-------------------\")\n",
    "            label_img = np.squeeze(label_img)\n",
    "            plt.imshow(label_img[test_index])\n",
    "            plt.show()\n",
    "            print(\"epoch end\")\n",
    "            \n",
    "            #print(\"loss : \", Vector_loss)\n",
    "            #print('\\n')\n",
    "            \n",
    "            \n",
    "            saver.save(self.sess, SAVE_PATH)\n",
    "            \n",
    "            #return rotate_img, label_img\n",
    "print(\"cell end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#roatation train\n",
    "with tf.Session() as sess:\n",
    "    obj = STN(sess = sess, batch_size=64, epochs=400)\n",
    "    obj.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#translation train\n",
    "with tf.Session() as sess:\n",
    "    obj = STN(sess = sess, batch_size=64, epochs=400)\n",
    "    obj.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
